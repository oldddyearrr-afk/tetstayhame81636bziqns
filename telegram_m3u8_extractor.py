#!/usr/bin/env python3
"""
Telegram M3U8 Stream Extractor
Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÙˆØ§Ø¨Ø· M3U8 Ù…Ù† Ø¨Ø«ÙˆØ« ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø¨Ø·Ø±ÙŠÙ‚Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
"""

import re
import json
import requests
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
import m3u8


class TelegramM3U8Extractor:
    """Ù…Ø³ØªØ®Ø±Ø¬ Ø±ÙˆØ§Ø¨Ø· M3U8 Ù…Ù† ØªÙ„ÙŠØ¬Ø±Ø§Ù…"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'en-US,en;q=0.9,ar;q=0.8',
            'Referer': 'https://web.telegram.org/',
            'Origin': 'https://web.telegram.org'
        })
    
    def parse_cookies_text(self, cookies_text):
        """ØªØ­ÙˆÙŠÙ„ Ù†Øµ Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ø¥Ù„Ù‰ dict"""
        cookies = {}
        
        for line in cookies_text.strip().split('\n'):
            line = line.strip()
            
            # ØªØ®Ø·ÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ©
            if not line or line.startswith('#'):
                continue
            
            # Netscape format: domain, flag, path, secure, expiration, name, value
            parts = line.split('\t')
            if len(parts) >= 7:
                cookies[parts[5]] = parts[6]
            # Simple format: name=value
            elif '=' in line:
                name, value = line.split('=', 1)
                cookies[name.strip()] = value.strip()
        
        return cookies
    
    def extract_m3u8_from_html(self, html_content, base_url):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÙˆØ§Ø¨Ø· M3U8 Ù…Ù† HTML"""
        m3u8_urls = []
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… regex
        patterns = [
            r'https?://[^\s<>"\']+?\.m3u8[^\s<>"\']*',
            r'"(https?://[^"]+\.m3u8[^"]*)"',
            r"'(https?://[^']+\.m3u8[^']*)'",
        ]
        
        for pattern in patterns:
            found = re.findall(pattern, html_content)
            m3u8_urls.extend(found)
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ script tags
        soup = BeautifulSoup(html_content, 'html.parser')
        scripts = soup.find_all('script')
        for script in scripts:
            if script.string:
                found = re.findall(r'https?://[^\s<>"\']+?\.m3u8[^\s<>"\']*', script.string)
                m3u8_urls.extend(found)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª
        unique_urls = list(set(m3u8_urls))
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© (master.m3u8 Ø£ÙˆÙ„Ø§Ù‹)
        unique_urls.sort(key=lambda x: (
            'master.m3u8' not in x.lower(),
            'playlist.m3u8' not in x.lower(),
            'index.m3u8' not in x.lower()
        ))
        
        return unique_urls
    
    def try_common_cdn_patterns(self, telegram_url):
        """Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù„Ù€ CDN ØªÙ„ÙŠØ¬Ø±Ø§Ù…"""
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ù‚Ù†Ø§Ø©/Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
        match = re.search(r't\.me/([^/]+)', telegram_url)
        if not match:
            return []
        
        # Ø£Ù†Ù…Ø§Ø· CDN Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…
        cdn_patterns = [
            'https://vcdn{}.telegram.org/file/stream/{}/master.m3u8',
            'https://vcdn{}.telegram.org/live/{}/index.m3u8',
            'https://cdn{}.telegram.org/file/{}/playlist.m3u8',
        ]
        
        possible_urls = []
        for i in range(1, 10):
            for pattern in cdn_patterns:
                # Ø¬Ø±Ø¨ Ø£Ø±Ù‚Ø§Ù… CDN Ù…Ø®ØªÙ„ÙØ©
                url = pattern.format(i, 'stream_id')
                possible_urls.append(url)
        
        return possible_urls
    
    def extract_from_telegram(self, telegram_url, cookies_text):
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø§Ø¨Ø· M3U8 Ù…Ù† ØªÙ„ÙŠØ¬Ø±Ø§Ù…
        
        Args:
            telegram_url: Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨Ø« ÙÙŠ ØªÙ„ÙŠØ¬Ø±Ø§Ù…
            cookies_text: Ù†Øµ Ø§Ù„ÙƒÙˆÙƒÙŠØ²
        
        Returns:
            dict: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
        """
        result = {
            'success': False,
            'stream_url': None,
            'method': None,
            'error': None,
            'tried_methods': []
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²
        try:
            cookies = self.parse_cookies_text(cookies_text)
            if cookies:
                self.session.cookies.update(cookies)
                result['tried_methods'].append('Parsed cookies successfully')
        except Exception as e:
            result['error'] = f'ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²: {str(e)}'
            return result
        
        # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 1: Ù…Ø­Ø§ÙˆÙ„Ø© ÙØªØ­ Ø§Ù„ØµÙØ­Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
        try:
            result['tried_methods'].append('Method 1: Direct page fetch')
            response = self.session.get(telegram_url, timeout=30)
            
            if response.status_code == 200:
                m3u8_urls = self.extract_m3u8_from_html(response.text, telegram_url)
                
                if m3u8_urls:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø£ÙˆÙ„ Ø±Ø§Ø¨Ø·
                    test_url = m3u8_urls[0]
                    try:
                        test_response = self.session.head(test_url, timeout=10)
                        if test_response.status_code in [200, 302, 301]:
                            result['success'] = True
                            result['stream_url'] = test_url
                            result['method'] = 'Direct HTML parsing'
                            return result
                    except:
                        pass
        except Exception as e:
            result['tried_methods'].append(f'Method 1 failed: {str(e)}')
        
        # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 2: Ù…Ø­Ø§ÙˆÙ„Ø© API calls Ù…Ø¨Ø§Ø´Ø±Ø©
        try:
            result['tried_methods'].append('Method 2: Telegram Web API')
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Telegram Web API
            api_url = 'https://web.telegram.org/k/'
            response = self.session.get(api_url, timeout=30)
            
            if response.status_code == 200:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† API endpoints ÙÙŠ Ø§Ù„ÙƒÙˆØ¯
                api_matches = re.findall(r'/api/\w+', response.text)
                result['tried_methods'].append(f'Found {len(api_matches)} API endpoints')
        except Exception as e:
            result['tried_methods'].append(f'Method 2 failed: {str(e)}')
        
        # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 3: Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        try:
            result['tried_methods'].append('Method 3: Common CDN patterns')
            possible_urls = self.try_common_cdn_patterns(telegram_url)
            
            for url in possible_urls[:5]:  # Ø¬Ø±Ø¨ Ø£ÙˆÙ„ 5 ÙÙ‚Ø·
                try:
                    test_response = self.session.head(url, timeout=5)
                    if test_response.status_code == 200:
                        result['success'] = True
                        result['stream_url'] = url
                        result['method'] = 'CDN pattern matching'
                        return result
                except:
                    continue
        except Exception as e:
            result['tried_methods'].append(f'Method 3 failed: {str(e)}')
        
        # Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø±Ù‚
        result['error'] = 'ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø§Ø¨Ø·. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ© (F12 â†’ Network â†’ m3u8)'
        
        return result


def test_extractor():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬"""
    extractor = TelegramM3U8Extractor()
    
    print("="*60)
    print("ğŸ“º Telegram M3U8 Extractor - Ø§Ø®ØªØ¨Ø§Ø±")
    print("="*60)
    
    # Ù…Ø«Ø§Ù„
    telegram_url = "https://t.me/example_channel"
    cookies_text = """
# Netscape HTTP Cookie File
.t.me	TRUE	/	FALSE	1234567890	stel_ssid	abc123def456
"""
    
    result = extractor.extract_from_telegram(telegram_url, cookies_text)
    
    print("\nğŸ“Š Ø§Ù„Ù†ØªÙŠØ¬Ø©:")
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    if result['success']:
        print(f"\nâœ… ØªÙ… Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬: {result['stream_url']}")
    else:
        print(f"\nâŒ ÙØ´Ù„: {result['error']}")
        print(f"\nğŸ” Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ù…Ø¬Ø±Ø¨Ø©:")
        for method in result['tried_methods']:
            print(f"   - {method}")


if __name__ == '__main__':
    test_extractor()
